# -*- coding: utf-8 -*-
"""202444792_210204598_206368527_Tarea-3_IA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i0jWKhlYeE88pLDIswn4DXeDY_YxmCaQ
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import accuracy_score

df = pd.read_csv('/content/sample_data/Churn_Modelling.csv')

print(df.head())
X = df.iloc[:, 3:13].values
y = df.iloc[:, 13].values
print(X)
print(y)
print(X.shape)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer

# Transformamos la columa de Geography a valores binarios
ct = ColumnTransformer([("Geography", OneHotEncoder(), [1])], remainder = 'passthrough')
X = ct.fit_transform(X)

# Se cambia la columna gender a valores binarios
labelencoder_X = LabelEncoder()
X[:, 4] = labelencoder_X.fit_transform(X[:, 4])
X = np.delete(X, 0, 1)

from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.65,random_state=70)
X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, train_size=0.5715,random_state=70)
print("Set de entrenamiento", X_train.shape)
print("Set de testeo", X_test.shape)
print("Set de validacion", X_valid.shape)

X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)
print(X_test)
y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)
print(y_test)

X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)
print(X_train)
y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)
print(y_train)

X_valid = tf.convert_to_tensor(X_valid, dtype=tf.float32)
print(X_valid)
y_valid = tf.convert_to_tensor(y_valid, dtype=tf.float32)
print(y_valid)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #normalizacion Z
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
print(X_train)

#Sin capa oculta

classifier = Sequential()
classifier.add(Dense(1, input_dim= 11, kernel_initializer='uniform',activation = 'sigmoid'))#solo una capa, la de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

#Una capa oculta (1)


classifier = Sequential()
classifier.add(Dense(1, input_dim= 11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1,  kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (3)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(3, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (5)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(5, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (10)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(10, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1,  kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (15)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(15, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (20)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(20, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (25)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(25, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (30)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(30, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Una capa oculta (35)
import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(35, input_dim=11, kernel_initializer='uniform', activation='relu')) #Input y capa oculta
classifier.add(Dense(units=1, kernel_initializer='uniform',activation = 'sigmoid'))#capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#parte 4
import keras
from keras.models import Sequential
from keras.layers import Dense

#Set 5
classifier = Sequential()
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Set 10

classifier = Sequential()
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#set 15

classifier = Sequential()
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Set 20

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 5, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 10, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 15, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

classifier.fit(X_test, y_test, epochs=100, batch_size=1)

classifier.fit(X_valid, y_valid, epochs=100, batch_size=1)

#Punto 5

#10%

from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train_sub, X_rem, y_train_sub, y_rem = train_test_split(X_train,y_train, train_size=0.1,random_state=87)
print("Set de entrenamiento 100%", X_train.shape)
print("Set de entrenamiento 10%", X_train_sub.shape)
# print("Set de validacion", X_valid.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #normalizacion Z
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
print(X_train_sub)
print(X_test)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.summary()

classifier.fit(X_train_sub, y_train_sub, epochs=100, batch_size=1)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

accuracy_score(y_test,y_pred)

#20%

from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train_sub, X_rem, y_train_sub, y_rem = train_test_split(X_train,y_train, train_size=0.2,random_state=87)
print("Set de entrenamiento 100%", X_train.shape)
print("Set de entrenamiento 20%", X_train_sub.shape)
print("Set de validacion", X_valid.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #normalizacion Z
X_train_sub = sc.fit_transform(X_train_sub)
X_test = sc.transform(X_test)
print(X_train_sub)
print(X_test)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train_sub, y_train_sub, epochs=100, batch_size=1)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

accuracy_score(y_test,y_pred)

#40%

from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train_sub, X_rem, y_train_sub, y_rem = train_test_split(X_train,y_train, train_size=0.4,random_state=87)
print("Set de entrenamiento 100%", X_train.shape)
print("Set de entrenamiento 40%", X_train_sub.shape)
#print("Set de validacion", X_valid.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #normalizacion Z
X_train_sub = sc.fit_transform(X_train_sub)
X_test = sc.transform(X_test)
print(X_train_sub)
print(X_test)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train_sub, y_train_sub, epochs=100, batch_size=1)

accuracy_score(y_test,y_pred)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

accuracy_score(y_test,y_pred)

#60%

from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train_sub, X_rem, y_train_sub, y_rem = train_test_split(X_train,y_train, train_size=0.6,random_state=87)
print("Set de entrenamiento 100%", X_train.shape)
print("Set de entrenamiento 10%", X_train_sub.shape)
print("Set de validacion", X_valid.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #normalizacion Z
X_train_sub = sc.fit_transform(X_train_sub)
X_test = sc.transform(X_test)
print(X_train_sub)
print(X_test)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train_sub, y_train_sub, epochs=100, batch_size=1)

accuracy_score(y_test, y_pred)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

accuracy_score(y_test,y_pred)

#80

from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train_sub, X_rem, y_train_sub, y_rem = train_test_split(X_train,y_train, train_size=0.8,random_state=87)
print("Set de entrenamiento 100%", X_train.shape)
print("Set de entrenamiento 10%", X_train_sub.shape)
print("Set de validacion", X_valid.shape)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() #normalizacion Z
X_train_sub = sc.fit_transform(X_train_sub)
X_test = sc.transform(X_test)
print(X_train_sub)
print(X_test)

classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train_sub, y_train_sub, epochs=100, batch_size=1)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

accuracy_score(y_test,y_pred)

#100
# ya fue ejecutado anteriormente
classifier = Sequential()
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu', input_dim = 11)) # Capa de entrada y oculta
classifier.add(Dense(units = 20, kernel_initializer='uniform', activation = 'relu')) #Capa oculta
classifier.add(Dense(units = 1, kernel_initializer= 'uniform', activation = 'sigmoid'))# Capa de salida
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.fit(X_train, y_train, epochs=100, batch_size=1)

y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)

accuracy_score(y_test,y_pred)

import matplotlib.pyplot as plt
import numpy as np

x = np.array([10,20,40,60,80,100])
y = np.array([0.826,0.823,0.84,0.842,0.832,0.805])

plt.scatter(x, y)
plt.show()

#punto 6

from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
#X_rem es equivalente a los 3500 datos restantes, con el fin de poder dividir los datos en validacion y testeo

X_train_sub, X_rem, y_train_sub, y_rem = train_test_split(X_train,y_train, train_size=0.1,random_state=87)
print("Set de entrenamiento 100%", X_train.shape)
print("Set de entrenamiento 10%", X_train_sub.shape)

wcss = []

for i in range(1,12):
  kmeans = KMeans(n_clusters = i,max_iter=300)
  kmeans.fit(X_train_sub)
  wcss.append(kmeans.inertia_)

plt.plot(range(1,12),wcss)
plt.title("K-means")
plt.xlabel("Numero de clusters")
plt.ylabel("WCSS")
plt.show

clustering = KMeans(n_clusters = 4,max_iter=300)
clustering.fit(X_train_sub)

df = pd.DataFrame(X_train_sub,columns=['Geography_1','Geography_2','CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCard','isActiveMember','EstimatedSalary'])

df.head()

df['KMeans_Cluster'] = clustering.labels_

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca_churn = pca.fit_transform(df)
pca_churn_df = pd.DataFrame(data = pca_churn,columns = ['Componente_1','Componente_2'])
pca_2 = pd.concat([pca_churn_df,df[['KMeans_Cluster']]],axis=1)
pca_2

fig = plt.figure(figsize=(6,6))
ax = fig.add_subplot(1,1,1)
ax.set_xlabel('Componente 1',fontsize=15)
ax.set_ylabel('Componente 2',fontsize=15)
ax.set_title('Componentes Principales',fontsize=20)
color_theme=np.array(['blue','green','orange','red'])
ax.scatter(x=pca_2.Componente_1,y=pca_2.Componente_2,c=color_theme[pca_2.KMeans_Cluster],s=50)
plt.show()